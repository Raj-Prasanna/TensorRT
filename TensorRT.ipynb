{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook explores TensorRT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "from torchvision import datasets, models\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from onnx import ModelProto\n",
    "import tensorrt as trt\n",
    "import pycuda.autoinit\n",
    "import pycuda.driver as cuda\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking if CUDA is available and assigning the compute available to device variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "    \n",
    "else:\n",
    "    device = 'cpu'\n",
    "    \n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using data augmentation for better tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([transforms.RandomHorizontalFlip(p=0.5),\n",
    "                                      transforms.RandomRotation(20),\n",
    "                                      transforms.RandomGrayscale(p=0.2),\n",
    "                                      transforms.ToTensor(), \n",
    "                                      transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))])\n",
    "test_transform = transforms.Compose([transforms.ToTensor(),\n",
    "                               transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = datasets.CIFAR10(root='data', train = True, download = True, transform = train_transform)\n",
    "test_data = datasets.CIFAR10(root='data', train = False, download = True, transform = test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train = len(train_data)\n",
    "num_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = list(range(num_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_size = 0.04\n",
    "split = int(np.floor((val_size * num_train)))\n",
    "split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx, val_idx = indices[split:],indices[:split]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "val_sampler = SubsetRandomSampler(val_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size = batch_size, sampler = train_sampler)\n",
    "val_loader = torch.utils.data.DataLoader(train_data, batch_size = batch_size, sampler = val_sampler)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_batches = len(test_loader)\n",
    "no_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "           'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "no_classes = len(classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    img = img / 2 + 0.5\n",
    "    plt.imshow(np.transpose(img,(1,2,0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_iter = iter(train_loader)\n",
    "images, labels = data_iter.next()\n",
    "images = images.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(25, 4))\n",
    "\n",
    "for im in np.arange(batch_size):\n",
    "    ax = fig.add_subplot(2, batch_size/2, im+1, xticks=[], yticks=[])\n",
    "    imshow(images[im])\n",
    "    ax.set_title(classes[labels[im]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom model definition just to experiment TensorRT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, padding = 1)\n",
    "        self.conv2 = nn.Conv2d(32,32, 3, padding = 1)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(32, 64, 3, padding = 1)\n",
    "        self.conv4 = nn.Conv2d(64, 64, 3, padding = 1)\n",
    "        \n",
    "        self.conv5 = nn.Conv2d(64, 128, 3, padding = 1)\n",
    "        self.conv6 = nn.Conv2d(128,128, 3, padding = 1)\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "        self.drop = nn.Dropout(0.4)\n",
    "        \n",
    "        self.fc1 = nn.Linear(2048,512)\n",
    "        self.fc2 = nn.Linear(512,128)\n",
    "        self.fc3 = nn.Linear(128, 10)\n",
    "        \n",
    "    def forward (self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.drop(x)\n",
    "        \n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.drop(x)\n",
    "        \n",
    "        x = F.relu(self.conv5(x))\n",
    "        x = F.relu(self.conv6(x))\n",
    "        \n",
    "        x = self.pool(x)\n",
    "        x = self.drop(x)\n",
    "        \n",
    "        x = x.view(x.shape[0], -1)\n",
    "        \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.drop(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.drop(x)\n",
    "        x = F.log_softmax(self.fc3(x), dim =1)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()\n",
    "\n",
    "model.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if type(m) == nn.Conv2d or type(m) == nn.Linear:\n",
    "        nn.init.xavier_uniform(m.weight)\n",
    "        \n",
    "model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_epochs = 1+10\n",
    "\n",
    "val_loss_min = np.Inf\n",
    "\n",
    "for epoch in range (1, no_epochs):\n",
    "    \n",
    "    start = time()\n",
    "    \n",
    "    train_loss = 0\n",
    "    train_acc = 0\n",
    "    val_loss = 0\n",
    "    val_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    for data, target in train_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "                \n",
    "        output = model(data)\n",
    "        \n",
    "        loss = criterion(output, target)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        #with amp.scale_loss(loss,optimizer) as scaled_loss:\n",
    "        #    scaled_loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        _,pred = torch.max(output, dim=1)\n",
    "        \n",
    "        equals = pred == target.view(*pred.shape)\n",
    "        \n",
    "        train_acc += torch.mean(equals.type(torch.FloatTensor))\n",
    "        \n",
    "    model.eval()\n",
    "    for data, target in val_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        output = model(data)\n",
    "        \n",
    "        loss = criterion(output, target)\n",
    "    \n",
    "        val_loss += loss.item()\n",
    "        \n",
    "        _,pred = torch.max(output, dim=1)\n",
    "        \n",
    "        equals = pred == target.view(*pred.shape)\n",
    "        \n",
    "        val_acc += torch.mean(equals.type(torch.FloatTensor))\n",
    "        \n",
    "    train_loss = train_loss / len(train_loader)\n",
    "    train_acc = train_acc * 100 / len(train_loader)\n",
    "    val_loss = val_loss / len(val_loader)\n",
    "    val_acc = val_acc * 100 / len(val_loader)\n",
    "    \n",
    "    end = time()\n",
    "    taken = end - start\n",
    "    \n",
    "    print('Epoch: {} \\tTime: {:.3f} \\nTraining Loss: {:.6f} \\tTraining Acc: {:.2f} \\tValidation Loss: {:.6f} \\tValidation Acc: {:.2f}'.format(epoch, taken, train_loss, train_acc, val_loss, val_acc))\n",
    "    \n",
    "    if val_loss <= val_loss_min:\n",
    "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(val_loss_min, val_loss))\n",
    "        torch.save(model.state_dict(), 'model_cifar.pth')\n",
    "        val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_test = Net()\n",
    "model_test.load_state_dict(torch.load('model_cifar.pth'))\n",
    "model_test = model_test.to(device)\n",
    "model_test.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference with native PyTorch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc = 0\n",
    "start = time()\n",
    "b_epoch = 10\n",
    "for i in range (b_epoch):\n",
    "\n",
    "    for data, target in test_loader:\n",
    "    \n",
    "        data, target = data.to(device), target.to(device)\n",
    "    \n",
    "        #optimizer.zero_grad()\n",
    "    \n",
    "        output = model_test(data)\n",
    "    \n",
    "        _,pred = torch.max(output, dim=1)\n",
    "    \n",
    "        equal = pred == target.view(*pred.shape)\n",
    "    \n",
    "        test_acc += torch.mean(equal.type(torch.FloatTensor))\n",
    "\n",
    "test_acc /= b_epoch\n",
    "taken = time() - start\n",
    "print(\"Accuracy is: {:.2f}%\".format(test_acc * 100 /len(test_loader)))\n",
    "print(\"Time taken: {:.2f}s\".format(taken))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting model in .pth to .onnx format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_path = \"../workspace/model_cifar.onnx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine_name = \"../workspace/model_fp16.plan\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (batch_size,3,32,32)\n",
    "inputs = torch.ones(*input_shape)\n",
    "inputs = inputs.to(device)\n",
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.onnx.export(model_test, inputs, onnx_path, input_names = None, output_names = None, dynamic_axes = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorRT flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRT_LOGGER = trt.Logger(trt.Logger.WARNING)\n",
    "trt_runtime = trt.Runtime(TRT_LOGGER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_engine(onnx_path, shape = [32,3,32,32]):\n",
    "\n",
    "    with trt.Builder(TRT_LOGGER) as builder,builder.create_builder_config() as config, builder.create_network(1) as network, trt.OnnxParser(network, TRT_LOGGER) as parser:\n",
    "        builder.fp16_mode = True\n",
    "        \n",
    "        profile = builder.create_optimization_profile()\n",
    "        config.max_workspace_size = (3072 << 20)\n",
    "        config.add_optimization_profile(profile)\n",
    "        with open(onnx_path, 'rb') as model:\n",
    "            parser.parse(model.read())\n",
    "        network.get_input(0).shape = shape\n",
    "        engine = builder.build_cuda_engine(network)\n",
    "        return engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_engine(engine, file_name):\n",
    "    buf = engine.serialize()\n",
    "    with open(file_name, 'wb') as f:\n",
    "        f.write(buf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_engine(trt_runtime, plan_path):\n",
    "    with open(engine_path, 'rb') as f:\n",
    "        engine_data = f.read()\n",
    "    engine = trt_runtime.deserialize_cuda_engine(engine_data)\n",
    "    return engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelProto()\n",
    "with open(onnx_path, \"rb\") as f:\n",
    "    model.ParseFromString(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d0 = model.graph.input[0].type.tensor_type.shape.dim[1].dim_value\n",
    "d1 = model.graph.input[0].type.tensor_type.shape.dim[2].dim_value\n",
    "d2 = model.graph.input[0].type.tensor_type.shape.dim[3].dim_value\n",
    "shape = [batch_size , d0, d1 ,d2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = build_engine(onnx_path, shape= shape)\n",
    "save_engine(engine, engine_name) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_to_buffer(pics, pagelocked_buffer):\n",
    "    preprocessed = np.asarray(pics).ravel()\n",
    "    np.copyto(pagelocked_buffer, preprocessed) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_inference(engine, pics_1, h_input_1, d_input_1, h_output, d_output, stream, batch_size):\n",
    "    \n",
    "    load_images_to_buffer(pics_1, h_input_1)\n",
    "     \n",
    "    with engine.create_execution_context() as context:\n",
    "        # Transfer input data to the GPU.\n",
    "        cuda.memcpy_htod_async(d_input_1, h_input_1, stream)\n",
    "\n",
    "        # Run inference.\n",
    "\n",
    "        context.profiler = trt.Profiler()\n",
    "        context.execute(batch_size=batch_size, bindings=[int(d_input_1), int(d_output)])\n",
    "\n",
    "        # Transfer predictions back from the GPU.\n",
    "        cuda.memcpy_dtoh_async(h_output, d_output, stream)\n",
    "        # Synchronize the stream\n",
    "        stream.synchronize()\n",
    "        # Return the host output.\n",
    "        out = (h_output)\n",
    "        return out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def allocate_buffers(engine):\n",
    "        \n",
    "    # host cpu mem\n",
    "    h_in_size = trt.volume(engine.get_binding_shape(0))\n",
    "    h_out_size = trt.volume(engine.get_binding_shape(1))\n",
    "        \n",
    "    h_in_dtype = trt.nptype(engine.get_binding_dtype(0))\n",
    "    h_out_dtype = trt.nptype(engine.get_binding_dtype(1))\n",
    "    \n",
    "    h_input = cuda.pagelocked_empty(h_in_size, h_in_dtype)\n",
    "    h_output = cuda.pagelocked_empty(h_out_size, h_out_dtype)\n",
    "    \n",
    "    # allocate gpu mem\n",
    "    d_input = cuda.mem_alloc(h_input.nbytes)\n",
    "    d_output = cuda.mem_alloc(h_output.nbytes)\n",
    "    stream = cuda.Stream()\n",
    "    \n",
    "    return h_input, d_input, h_output, d_output, stream"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference with TensorRT engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc = 0\n",
    "start = time()\n",
    "\n",
    "for i in range(b_epoch):\n",
    "    for image,label in test_loader:\n",
    "        temp = np.asarray(image,dtype=np.float32)\n",
    "        \n",
    "        h_input, d_input, h_output, d_output, stream = allocate_buffers(engine)\n",
    "        out = do_inference(engine, temp, h_input, d_input, h_output, d_output, stream, batch_size)\n",
    "        out = torch.from_numpy(out.reshape(batch_size,-1))\n",
    "        \n",
    "        _,pred = torch.max(out, dim=1)\n",
    "        equal = pred == label.view(*pred.shape)\n",
    "    \n",
    "        test_acc += torch.mean(equal.type(torch.FloatTensor))\n",
    "\n",
    "test_acc /= b_epoch\n",
    "taken = time() - start\n",
    "print(\"Accuracy is: {:.2f}%\".format(test_acc * 100 /len(test_loader)))\n",
    "print(\"Time taken: {:.2f}s\".format(taken))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
